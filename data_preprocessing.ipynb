{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from utils.plotting import plot_trajectory\n",
    "from utils.processing import (\n",
    "    normalize,\n",
    "    open_file,\n",
    "    cut_jumps\n",
    "    )\n",
    "\n",
    "DATA_DIR = 'dataset'\n",
    "PREPROC_DATA_DIR = 'preprocessed_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we preprocess data:\n",
    "\n",
    "1. Load trajectories, remove mice jumps onto walls\n",
    "\n",
    "2. Normalize x and y values in [-40, 40] range\n",
    "\n",
    "3. Adress gaps in recordings and inconsistent dt\n",
    "\n",
    "4. Resample data to given sampling rate\n",
    "\n",
    "5. Add new infromation (i.e. angles, delta angels, etc.)\n",
    "\n",
    "6. Save preprocessed data to new files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = sorted(glob(os.path.join(DATA_DIR, '*.txt')))\n",
    "datasets = {}\n",
    "for nam in dataset_names:\n",
    "    k = Path(nam).stem\n",
    "    v = open_file(nam)\n",
    "    datasets[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1_1 = datasets['Trace_1.1']\n",
    "tr1_2 = datasets['Trace_1.2']  \n",
    "tr2 = datasets['Trace_2']\n",
    "tr5 = datasets['Trace_5']\n",
    "\n",
    "tr4 = cut_jumps(datasets['Trace_4'], xmax=40.4, xmin=-38.1, ymax=28.3, ymin=-47.6)\n",
    "tr3 = cut_jumps(datasets['Trace_3'], xmax=46.8, xmin=-48, ymax=46, ymin=-47)\n",
    "tr6 = cut_jumps(datasets['Trace_6'], xmax=45, xmin=-45, ymax=45, ymin=-42.2)\n",
    "tr7 = cut_jumps(datasets['Trace_7'], xmax=35, xmin=-38.7, ymax=40, ymin=-32)\n",
    "tr91 = cut_jumps(datasets['Trace_9.1'], xmax=42.5, xmin=-43.7, ymax=42.5, ymin=-42.7)\n",
    "tr92 = cut_jumps(datasets['Trace_9.2'], xmax=36.3, xmin=-46.5, ymax=45.4, ymin=-47.3)\n",
    "\n",
    "dfs = [tr1_1, tr1_2, tr2, tr3, tr4, tr5, tr6, tr7, tr91, tr92]\n",
    "dfs_names = ['tr1_1', 'tr1_2', 'tr2','tr3','tr4','tr5','tr6','tr7', 'tr91','tr92']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dropna = []\n",
    "\n",
    "# Find data that has Nans \n",
    "for i in range(len(dfs)):\n",
    "    print(dfs_names[i], dfs[i].shape)\n",
    "    dfs_dropna.append(dfs[i].dropna())\n",
    "    print(dfs[i].shape)\n",
    "    dropped_num = dfs[i].shape[0] - dfs_dropna[i].shape[0]\n",
    "    print('Dropped: ', dropped_num)\n",
    "    if dropped_num > 0:\n",
    "        print('!!!: ', i, dfs_names[i])\n",
    "    print('--'*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### STOPED HERE -===================================================\n",
    "# ======================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Find dt tresholds by hands for each traj, save\n",
    "\n",
    "## 2. Create function:\n",
    "def divide_traj_by_nans():\n",
    "    pass\n",
    "# a. Drop nans\n",
    "# b. Find places where dt > dt_treshold\n",
    "# c. Find idxs of start and end of this space period, save them to list \n",
    "# d. cut trajectory into subtrajectories by this periods\n",
    "# e. return original trajectory, cutted subset and list of cuts\n",
    "\n",
    "# So now we change a bit data structure:\n",
    "# from {'tr4': df} to {'tr4': [df1, df2, ...]}\n",
    "\n",
    "# Make resampling function, place it before all other functions, use after def divide_traj_by_nans()\n",
    "\n",
    "# Find and put into one place all functinos that add new columns to dataframe (angle, dangle, area, etc.)\n",
    "\n",
    "# Save all preprocessed datasets to work with them further!\n",
    "\n",
    "# Think how all other functions will operate with new data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find dt tresholds by hands for each traj, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to adress recording gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_traj_by_nans(): # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(): # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessed_data():  # TODO\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
